{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunnygupta3535/Notebook/blob/main/pdf_processor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FMYF8AfniQo"
      },
      "source": [
        "# PDF Processor (RAG Pipeline)\n",
        "\n",
        "This notebook handles the PDF processing part of the RAG pipeline using Docling.\n",
        "It scans a directory for PDF files, converts them to Markdown, and splits them by page."
      ],
      "id": "6FMYF8AfniQo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83cdf2b7"
      },
      "source": [
        "# README: PDF Processor (RAG Pipeline)"
      ],
      "id": "83cdf2b7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45299b6b"
      },
      "source": [
        "This notebook is designed to process PDF documents using the Docling library, convert them into Markdown format, and then split the content by page. This process is a crucial first step in building a Retrieval Augmented Generation (RAG) pipeline, where text content needs to be extracted and chunked for efficient retrieval."
      ],
      "id": "45299b6b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7c7b982"
      },
      "source": [
        "## Features\n",
        "\n",
        "- Scans a specified directory for PDF files.\n",
        "- Uses `docling` to convert PDFs to Markdown.\n",
        "- Supports Optical Character Recognition (OCR) for scanned PDFs.\n",
        "- Splits the generated Markdown content into individual pages.\n",
        "- Saves both the full Markdown document and individual page Markdowns to an output directory.\n"
      ],
      "id": "c7c7b982"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "286e6cbc"
      },
      "source": [
        "## Setup\n",
        "\n",
        "1.  **Install Dependencies**: The notebook begins by installing the `docling` library.\n",
        "    ```bash\n",
        "    !pip install docling\n",
        "    ```\n",
        "\n",
        "2.  **Prepare Data**: Create a `data` directory in the same location as your notebook and place all the PDF files you wish to process inside it.\n",
        "    ```bash\n",
        "    # Example: Create a 'data' directory and upload your PDFs\n",
        "    !mkdir -p data\n",
        "    # Upload your PDF files to the 'data' directory in Colab's file browser\n",
        "    ```\n",
        "\n",
        "3.  **Configure Output**: An `output` directory will be created automatically to store the processed Markdown files.\n",
        "\n"
      ],
      "id": "286e6cbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dba3f6b8"
      },
      "source": [
        "## Usage\n",
        "\n",
        "Simply run all cells in the notebook. The script will:\n",
        "\n",
        "1.  Initialize the `PDFProcessor` with OCR enabled.\n",
        "2.  Scan the `data` directory for all `.pdf` files.\n",
        "3.  Process each PDF file: convert it to Markdown, and then split it into page-wise Markdown files.\n",
        "4.  Save the generated Markdown files (full document and individual pages) into subdirectories within the `output` folder, named after the original PDF file.\n",
        "\n"
      ],
      "id": "dba3f6b8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b27655a"
      },
      "source": [
        "## Output\n",
        "\n",
        "For each PDF file, the following output will be generated in a dedicated subdirectory within the `output` folder:\n",
        "\n",
        "-   `<pdf_name>_full.md`: The complete Markdown content of the PDF.\n",
        "-   `<pdf_name>_page_001.md`, `<pdf_name>_page_002.md`, etc.: Individual Markdown files for each page of the PDF.\n",
        "\n",
        "Example output structure:\n",
        "\n",
        "```\n",
        "output/\n",
        "├── CIGU-2025-0002/\n",
        "│   ├── CIGU-2025-0002_full.md\n",
        "│   ├── CIGU-2025-0002_page_001.md\n",
        "│   ├── CIGU-2025-0002_page_002.md\n",
        "│   └── ...\n",
        "├── CIGU-2025-0003/\n",
        "│   ├── CIGU-2025-0003_full.md\n",
        "│   ├── CIGU-2025-0003_page_001.md\n",
        "│   └── ...\n",
        "└── ...\n",
        "```\n",
        "\n",
        "The `results` variable in the kernel contains a list of dictionaries, where each dictionary represents a processed page and includes its page number, file path, content, and source PDF."
      ],
      "id": "5b27655a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bd5668a"
      },
      "source": [
        "## Important Notes\n",
        "\n",
        "-   The `HF_TOKEN` from `google.colab.userdata` is accessed, suggesting potential integration with Hugging Face models, although its direct usage isn't explicitly shown in the provided code snippet.\n",
        "-   Errors during PDF processing for individual files will be logged, and the processing will continue for other files.\n"
      ],
      "id": "4bd5668a"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "s9gd99qsniQr",
        "outputId": "8a4e67b9-5c16-45ee-8802-9074c1ded0be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docling\n",
            "  Downloading docling-2.64.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.12.3)\n",
            "Collecting docling-core<3.0.0,>=2.50.1 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading docling_core-2.54.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting docling-parse<5.0.0,>=4.7.0 (from docling)\n",
            "  Downloading docling_parse-4.7.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting docling-ibm-models<4,>=3.9.1 (from docling)\n",
            "  Downloading docling_ibm_models-3.10.3-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pypdfium2!=4.30.1,<5.0.0,>=4.30.0 (from docling)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.12.0)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.12/dist-packages (from docling) (0.36.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from docling) (2.32.4)\n",
            "Collecting rapidocr<4.0.0,>=3.3 (from docling)\n",
            "  Downloading rapidocr-3.4.3-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2025.11.12)\n",
            "Requirement already satisfied: rtree<2.0.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.4.1)\n",
            "Collecting typer<0.20.0,>=0.12.5 (from docling)\n",
            "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from docling) (4.13.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2.2.2)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
            "  Downloading marko-2.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.12/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: lxml<7.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (6.0.2)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (11.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from docling) (4.67.1)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.6.0)\n",
            "Collecting pylatexenc<3.0,>=2.10 (from docling)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.16.3)\n",
            "Requirement already satisfied: accelerate<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.12.0)\n",
            "Collecting polyfactory>=2.22.2 (from docling)\n",
            "  Downloading polyfactory-3.1.0-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (6.0.3)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.9.0+cu126)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.15.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.50.1->docling-core[chunking]<3.0.0,>=2.50.1->docling) (4.25.1)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.50.1->docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.50.1->docling-core[chunking]<3.0.0,>=2.50.1->docling) (0.9.0)\n",
            "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.50.1->docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading latex2mathml-3.78.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tree-sitter<1.0.0,>=0.23.2 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading tree_sitter-0.25.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10.0 kB)\n",
            "Collecting tree-sitter-python<1.0.0,>=0.23.6 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading tree_sitter_python-0.25.0-cp310-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (1.9 kB)\n",
            "Collecting tree-sitter-c<1.0.0,>=0.23.4 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading tree_sitter_c-0.24.1-cp310-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting tree-sitter-java<1.0.0,>=0.23.5 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading tree_sitter_java-0.23.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting tree-sitter-javascript<1.0.0,>=0.23.1 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading tree_sitter_javascript-0.25.0-cp310-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting tree-sitter-typescript<1.0.0,>=0.23.2 (from docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading tree_sitter_typescript-0.23.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from docling-core[chunking]<3.0.0,>=2.50.1->docling) (4.57.3)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.12/dist-packages (from docling-ibm-models<4,>=3.9.1->docling) (0.24.0+cu126)\n",
            "Collecting jsonlines<5.0.0,>=3.1.0 (from docling-ibm-models<4,>=3.9.1->docling)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (1.2.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Collecting faker>=5.0.0 (from polyfactory>=2.22.2->docling)\n",
            "  Downloading faker-38.2.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.3.0->docling) (1.2.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting pyclipper>=1.2.0 (from rapidocr<4.0.0,>=3.3->docling)\n",
            "  Downloading pyclipper-1.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: opencv_python>=4.5.1.48 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (4.12.0.88)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (1.17.0)\n",
            "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (2.1.2)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from rapidocr<4.0.0,>=3.3->docling) (2.3.0)\n",
            "Collecting colorlog (from rapidocr<4.0.0,>=3.3->docling)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (8.3.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.20.0,>=0.12.5->docling) (13.9.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines<5.0.0,>=3.1.0->docling-ibm-models<4,>=3.9.1->docling) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.50.1->docling-core[chunking]<3.0.0,>=2.50.1->docling) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.50.1->docling-core[chunking]<3.0.0,>=2.50.1->docling) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.50.1->docling-core[chunking]<3.0.0,>=2.50.1->docling) (0.30.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (2.19.2)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.50.1->docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.50.1->docling) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.50.1->docling) (0.22.1)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->rapidocr<4.0.0,>=3.3->docling) (4.9.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.20.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.0.3)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.12/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.50.1->docling) (0.70.16)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.50.1->docling) (0.3.8)\n",
            "Downloading docling-2.64.1-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.8/274.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_core-2.54.1-py3-none-any.whl (200 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.10.3-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-4.7.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading marko-2.2.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polyfactory-3.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rapidocr-3.4.3-py3-none-any.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-38.2.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading latex2mathml-3.78.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.4.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (978 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m978.2/978.2 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading tree_sitter-0.25.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (635 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m635.4/635.4 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_c-0.24.1-cp310-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_java-0.23.5-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_javascript-0.25.0-cp310-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_python-0.25.0-cp310-abi3-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tree_sitter_typescript-0.23.2-cp39-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (344 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Downloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=02dc9293b9ae31294df2e42c6d6369ec68bd0c81221498d999efe1b763314259\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: pylatexenc, filetype, XlsxWriter, tree-sitter-typescript, tree-sitter-python, tree-sitter-javascript, tree-sitter-java, tree-sitter-c, tree-sitter, python-docx, pypdfium2, pyclipper, mpire, marko, latex2mathml, jsonref, jsonlines, faker, colorlog, rapidocr, python-pptx, polyfactory, typer, semchunk, docling-core, docling-parse, docling-ibm-models, docling\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.20.0\n",
            "    Uninstalling typer-0.20.0:\n",
            "      Successfully uninstalled typer-0.20.0\n",
            "Successfully installed XlsxWriter-3.2.9 colorlog-6.10.1 docling-2.64.1 docling-core-2.54.1 docling-ibm-models-3.10.3 docling-parse-4.7.2 faker-38.2.0 filetype-1.2.0 jsonlines-4.0.0 jsonref-1.1.0 latex2mathml-3.78.1 marko-2.2.1 mpire-2.10.2 polyfactory-3.1.0 pyclipper-1.4.0 pylatexenc-2.10 pypdfium2-4.30.0 python-docx-1.2.0 python-pptx-1.0.2 rapidocr-3.4.3 semchunk-2.2.2 tree-sitter-0.25.2 tree-sitter-c-0.24.1 tree-sitter-java-0.23.5 tree-sitter-javascript-0.25.0 tree-sitter-python-0.25.0 tree-sitter-typescript-0.23.2 typer-0.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install docling"
      ],
      "id": "s9gd99qsniQr"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iQrK-V8KniQs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "from docling.document_converter import DocumentConverter\n",
        "from docling.datamodel.base_models import InputFormat\n",
        "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
        "from docling.document_converter import PdfFormatOption\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
        "logger = logging.getLogger(__name__)"
      ],
      "id": "iQrK-V8KniQs"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ruAcCnHxniQs",
        "outputId": "615f2603-9163-4ce6-8d8e-080500927901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Directory: /content/data\n",
            "Output Directory: /content/output\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "DATA_DIR = Path(\"data\")\n",
        "OUTPUT_DIR = Path(\"output\")\n",
        "\n",
        "print(f\"Data Directory: {DATA_DIR.resolve()}\")\n",
        "print(f\"Output Directory: {OUTPUT_DIR.resolve()}\")"
      ],
      "id": "ruAcCnHxniQs"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CRdo-nVRniQt"
      },
      "outputs": [],
      "source": [
        "class PDFProcessor:\n",
        "    \"\"\"Process PDFs using Docling and export to markdown.\"\"\"\n",
        "\n",
        "    def __init__(self, output_dir: Optional[str] = None):\n",
        "        self.output_dir = Path(output_dir or OUTPUT_DIR)\n",
        "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Configure PDF pipeline options\n",
        "        pipeline_options = PdfPipelineOptions()\n",
        "        pipeline_options.do_ocr = True  # Enable OCR for scanned PDFs\n",
        "\n",
        "        self.converter = DocumentConverter(\n",
        "            format_options={\n",
        "                InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
        "            }\n",
        "        )\n",
        "\n",
        "    def process_pdf(self, pdf_path: str) -> list[dict]:\n",
        "        \"\"\"\n",
        "        Process a single PDF and generate page-wise markdown files.\n",
        "\n",
        "        Args:\n",
        "            pdf_path: Path to the PDF file\n",
        "\n",
        "        Returns:\n",
        "            List of dicts with page info and markdown content\n",
        "        \"\"\"\n",
        "        pdf_path = Path(pdf_path)\n",
        "        if not pdf_path.exists():\n",
        "            raise FileNotFoundError(f\"PDF not found: {pdf_path}\")\n",
        "\n",
        "        # Convert PDF\n",
        "        logger.info(f\"Converting {pdf_path.name}...\")\n",
        "        result = self.converter.convert(pdf_path)\n",
        "\n",
        "        # Get the document\n",
        "        doc = result.document\n",
        "\n",
        "        # Export full document to markdown\n",
        "        full_md = doc.export_to_markdown()\n",
        "\n",
        "        # Create output directory for this PDF\n",
        "        pdf_output_dir = self.output_dir / pdf_path.stem\n",
        "        pdf_output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Save full markdown\n",
        "        full_md_path = pdf_output_dir / f\"{pdf_path.stem}_full.md\"\n",
        "        with open(full_md_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(full_md)\n",
        "\n",
        "        # Split by pages and save individual page files\n",
        "        pages = self._split_by_pages(doc, full_md)\n",
        "\n",
        "        page_files = []\n",
        "        for i, page_content in enumerate(pages, 1):\n",
        "            page_path = pdf_output_dir / f\"{pdf_path.stem}_page_{i:03d}.md\"\n",
        "            with open(page_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(page_content)\n",
        "\n",
        "            page_files.append({\n",
        "                'page_num': i,\n",
        "                'file_path': str(page_path),\n",
        "                'content': page_content,\n",
        "                'source_pdf': str(pdf_path),\n",
        "            })\n",
        "\n",
        "        return page_files\n",
        "\n",
        "    def _split_by_pages(self, doc, full_md: str) -> list[str]:\n",
        "        \"\"\"\n",
        "        Split document content by pages.\n",
        "        \"\"\"\n",
        "        pages = []\n",
        "\n",
        "        try:\n",
        "            if hasattr(doc, 'pages') and doc.pages:\n",
        "                for page in doc.pages:\n",
        "                    if hasattr(page, 'export_to_markdown'):\n",
        "                        pages.append(page.export_to_markdown())\n",
        "                    else:\n",
        "                        page_text = str(page) if page else \"\"\n",
        "                        pages.append(page_text)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        if not pages:\n",
        "            if '\\n---\\n' in full_md:\n",
        "                pages = full_md.split('\\n---\\n')\n",
        "            else:\n",
        "                pages = [full_md]\n",
        "\n",
        "        return pages\n",
        "\n",
        "    def process_all_pdfs(self, data_dir: Optional[str] = None) -> list[dict]:\n",
        "        \"\"\"\n",
        "        Process all PDFs in the data directory.\n",
        "        \"\"\"\n",
        "        data_dir = Path(data_dir or DATA_DIR)\n",
        "\n",
        "        all_pages = []\n",
        "        pdf_files = list(data_dir.glob(\"**/*.pdf\"))\n",
        "\n",
        "        print(f\"Found {len(pdf_files)} PDF files to process in {data_dir}\")\n",
        "\n",
        "        for pdf_path in pdf_files:\n",
        "            print(f\"Processing: {pdf_path.name}\")\n",
        "            try:\n",
        "                pages = self.process_pdf(pdf_path)\n",
        "                all_pages.extend(pages)\n",
        "                print(f\"  → Generated {len(pages)} page(s)\")\n",
        "            except Exception as e:\n",
        "                print(f\"  ✗ Error processing {pdf_path.name}: {e}\")\n",
        "\n",
        "        return all_pages"
      ],
      "id": "CRdo-nVRniQt"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D5Yyo5b4niQt",
        "outputId": "e2c06da0-2896-4845-9489-193fddf4ed51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO] 2025-12-10 00:50:16,453 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,455 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,508 [RapidOCR] download_file.py:60: File exists and is valid: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,510 [RapidOCR] main.py:50: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_det_infer.pth\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4 PDF files to process in data\n",
            "Processing: CIGU-2025-0002.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[INFO] 2025-12-10 00:50:16,791 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,792 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,797 [RapidOCR] download_file.py:60: File exists and is valid: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,798 [RapidOCR] main.py:50: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_ptocr_mobile_v2.0_cls_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,912 [RapidOCR] base.py:22: Using engine_name: torch\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:16,914 [RapidOCR] device_config.py:50: Using CPU device\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:17,007 [RapidOCR] download_file.py:60: File exists and is valid: /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
            "\u001b[32m[INFO] 2025-12-10 00:50:17,008 [RapidOCR] main.py:50: Using /usr/local/lib/python3.12/dist-packages/rapidocr/models/ch_PP-OCRv4_rec_infer.pth\u001b[0m\n",
            "WARNING:docling.models.rapid_ocr_model:RapidOCR returned empty result!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  → Generated 69 page(s)\n",
            "Processing: CIGU-2025-0003.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[33m[WARNING] 2025-12-10 00:55:50,954 [RapidOCR] main.py:123: The text detection result is empty\u001b[0m\n",
            "WARNING:docling.models.rapid_ocr_model:RapidOCR returned empty result!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  → Generated 11 page(s)\n",
            "Processing: Cyber-security-tips-by-cyber-dost.pdf\n",
            "  → Generated 45 page(s)\n",
            "Processing: ANUAL-2025-0001.pdf\n",
            "  → Generated 25 page(s)\n",
            "\n",
            "Total pages generated: 150\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HF_TOKEN')\n",
        "\n",
        "# Run Processing\n",
        "if __name__ == \"__main__\":\n",
        "    processor = PDFProcessor(output_dir=OUTPUT_DIR)\n",
        "\n",
        "    # Ensure data directory exists\n",
        "    if not DATA_DIR.exists():\n",
        "        print(f\"Warning: Data directory {DATA_DIR} does not exist!\")\n",
        "        print(\"Please create it and place PDF files there.\")\n",
        "    else:\n",
        "        results = processor.process_all_pdfs(data_dir=DATA_DIR)\n",
        "        print(f\"\\nTotal pages generated: {len(results)}\")"
      ],
      "id": "D5Yyo5b4niQt"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GaVgWZpwniQu",
        "outputId": "63183c6c-9c49-4ddb-853a-0d67ff3ff3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 154 markdown files in output directory:\n",
            " - CIGU-2025-0003_page_002.md\n",
            " - CIGU-2025-0003_page_011.md\n",
            " - CIGU-2025-0003_page_004.md\n",
            " - CIGU-2025-0003_page_008.md\n",
            " - CIGU-2025-0003_full.md\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "# Verify Output\n",
        "output_files = list(OUTPUT_DIR.glob(\"**/*.md\"))\n",
        "print(f\"Found {len(output_files)} markdown files in output directory:\")\n",
        "for f in output_files[:5]:\n",
        "    print(f\" - {f.name}\")\n",
        "if len(output_files) > 5:\n",
        "    print(\"...\")"
      ],
      "id": "GaVgWZpwniQu"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}